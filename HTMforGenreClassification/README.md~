# HTM for Musical Genre Classification

> Tied to issue #14 https://github.com/nupic-community/nupic.audio/issues/14

The paper "Musical Genre Classification of Audio Signals" ([1][2]) describes the creation of feature vectors from a variety of statistics; taken over short-time frame analysis windows, and longer texture windows (containing groups of analysis windows). Perfect for a variety of analysis as outlined below.

For a comparisons from supervised learning; in 2010 Hamel and Eck detailed "Learning features from music audio with deep belief networks" [3].

The idea is to implement the statistical analysis (via Marsyas, and possibly Sonic Visualizer), and **investigate the unsupervised recognition of musical genres**. An alternative is to train with musical styles rather than genre.

## Prerequisites

- Compilers and build system (GCC v2.8.x, build-essentials)
- Python (2.7 for NuPIC)
- NuPIC (incl. it's requirements, e.g. NumPy)
- [Optional] NuPIC.core library built locally and linked to local NuPIC
- Marsyas http://marsyas.info/ (GPL2 https://github.com/marsyas/marsyas)
- Python bindings for Marsyas [4]

> Marsyas (Music Analysis, Retrieval and Synthesis for Audio Signals) is an open source software framework for audio processing with specific emphasis on Music Information Retrieval applications. It has been designed and written by George Tzanetakis with help from students and researchers from around the world. Marsyas has been used for a variety of projects in both academia and industry.

Plus these additional packages (example for Debian-based Linux OS) -  
> sudo apt-get install g++ build-essential cmake cmake-curses-gui libasound2-dev libfreetype6-dev  
> sudo apt-get install swig python-dev ipython  
> sudo pip install matplotlib  
> sudo apt-get install python-matplotlib  

The freetype development library installation also makes sure the libpng package is installed.

### Optional

Sonic Visualizer and VAMP plugin SDK. With Marsyas re-built with VAMP support.

http://www.sonicvisualiser.org/  
http://www.vamp-plugins.org/

## Datasets

The instructions to install these two datasets into Marsyas are described in the doc/tour.texi file [5] (or it's HTML equivalent if docs have been built within a Marsyas repo clone).

Citation: 
> B. L. Sturm, "An Analysis of the GTZAN Music Genre Dataset", Proc. ACM Workshop MIRUM, Nara, Japan, Nov. 2012

### Genres

genres.tar.gz - 1.14 GB 

The dataset consists of 1000 audio tracks each 30 seconds long. It contains 10 genres, each represented by 100 tracks. The tracks are all 22050Hz Mono 16-bit audio files in .wav format.

### Music and Speech

music_speech.tar.gz - 283 MB

A similar dataset which was collected for the purposes of music/speech discrimination. The dataset consists of 120 tracks, each 30 seconds long. Each class (music/speech) has 60 examples. The tracks are all 22050Hz Mono 16-bit audio files in .wav format.

### Mocha TIMIT?

Phonetically balanced dataset for training an automatic speech recognition system. A set of 460 sentences designed to include the main connected speech processes in English (eg. assimilations, weak forms ..).

http://www.cstr.ed.ac.uk/research/projects/artic/mocha.html

## Planning

### Timbral Features
1 Spectral Centroid  
2 Spectral Rolloff  
3 Spectral Flux  
4 Time Domain Zero Crossing  
5 Mel-Frequency Cepstral Coefficients  
6 Analysis and Texture windowing  
7 Low-Energy Feature  

A resulting feature vector for describing timbral texture consists of the following features: means and variances of spectral centroid, rolloff, flux, zero crossings over the texture
window (8), low energy (1), and means and variances of the first five MFCC coefficients over the texture window (excluding the coefficient corresponding to the DC component) resulting in a
19-dimensional feature vector.

### Rhythmic Content Features

> See [6] for description of the Continuous Wavelet Transfrom (Constant-Q filter).

DAUB4 filters proposed by Daubechies? I. Daubechies, “Orthonormal bases of compactly supported wavelets” Commun. Pure Appl. Math, vol. 41, pp. 909–996, 1988.

Wavelet transform, then for each octave frequency band;
- Full Wave Rectification
- Low-pass Filtering
- Downsampling
- Mean Removal
- Enhanced Autocorrelation
- Peak Detection and Histogram Calculation
- Beat Histogram Features
  
### Pitch Content Features

- Beat Determination
- MIDI Codes

### Auditory peripheral processing

- Outer and middle ear
- Cochlear filterbank
- Energy measures

## References

1 http://webhome.csc.uvic.ca/~gtzan/output/tsap02gtzan.pdf  
2 http://ismir2001.ismir.net/pdf/tzanetakis.pdf  
3 http://musicweb.ucsd.edu/~sdubnov/Mu270d/DeepLearning/FeaturesAudioEck.pdf  
4 http://marsology.blogspot.co.uk/2011/09/installing-marsyas-with-python-bindings.html  
5 https://github.com/rcrowder/marsyas/blob/master/doc/tour.texi  
6 http://uk.mathworks.com/help/wavelet/gs/continuous-wavelet-transform.html  
 
Loughlin, Atlas, Pitton, Proc. ICASSP '92  
Furui S., Proc. ICASSP '90 789-792 "Hierarchical spectral dynamics"  
Hermansky et al. Speech Communications, 4, 181-187  
Applebaum et al. Proc. EuroSpeech '91 1203-1206  
Seneff 1988 Journal of Phonetics 16, 55-76  
Meyer & Ainsworth, Royal Society (poster), 1992 "Processing in CN"  
AR Palmer & IM Winter "Coding in CN & VCN"  
